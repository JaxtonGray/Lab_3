{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lab 3\n",
    "------\n",
    "Welcome to lab 3, in this lab we will be doing the following:\n",
    "- Retrieving station data from the ECCC API\n",
    "- Creating thiessen polygons and calculating the area of each polygon\n",
    "- Gathering data from the ECCC API\n",
    "- Plotting and visualizing the data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Library Imports\n",
    "To run this lab you must have the following packages installed:\n",
    "- requests (to retrieve data from the API)\n",
    "- numpy (to manipulate the data)\n",
    "- pandas (to manipulate the data)\n",
    "- geopandas (to manipulate the data geospatially)\n",
    "- folium (for creating interactive maps)\n",
    "- matplotlib (for plotting and visualizing data)\n",
    "- shapely (for working with polygons)\n",
    "- scipy (for creating the Thiessen polygons)\n",
    "\n",
    "You can install these packages by running the following command in your terminal:\n",
    "```bash\n",
    "pip install requests numpy pandas geopandas shapely folium matplotlib shapely scipy\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import piplite\n",
    "await piplite.install(\"requests\")\n",
    "await piplite.install(\"numpy\")\n",
    "await piplite.install(\"pandas\")\n",
    "await piplite.install(\"geopandas\")\n",
    "await piplite.install(\"scipy\")\n",
    "await piplite.install(\"shapely\")\n",
    "await piplite.install(\"folium\")\n",
    "await piplite.install(\"matplotlib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load packages\n",
    "import io  # Input/Output library, base package already included in Python\n",
    "import datetime  # Date and time library, base package already included in Python\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import folium as fm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from shapely.geometry import Polygon\n",
    "from scipy.spatial import Voronoi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function Documentation and Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "The next code block contains functions I have created to help you with the lab, this block needs to be executed before you can carry on with the lab. While you do not need to understand the inner workings of these functions, you do need to know their arguments and what they return.\n",
    "\n",
    "Functions:\n",
    "- **bbox**: Create a geopandas dataframe with a box around a point\n",
    "  - Arguments:\n",
    "    - loc: a geopandas series with a point geometry\n",
    "    - distance: The distance in meters from the point to the edge of the box (in KM)\n",
    "  - Returns:\n",
    "    - A geopandas dataframe with a box around the point\n",
    "  - NOTE: This function works **REQUIRES** locations in a projected coordinate system\n",
    "- **retrieve_climate_stations**: Retrieve climate stations from ECCC's API\n",
    "  - Arguments:\n",
    "    - location: a geopandas series with a point geometry in a projected coordinate system (e.g. UTM)\n",
    "    - yearStart: Start year you want to the data to start from\n",
    "    - yearEnd: End year you want to the data to end at\n",
    "    - radial_distance: the distance in KM from the point to search for within the radial distance\n",
    "  - Returns:\n",
    "    - A geopandas dataframe with the stations in the bounding box that have daily data between both the start and end years, in the WGS84 coordinate system\n",
    "- **retrieve_weather_data**: Retrieve weather data from ECCC's API\n",
    "  - Arguments:\n",
    "    - stations: A dataframe with the stations you want to retrieve the data from (requires the columns 'STN_ID')\n",
    "    - startDate: Start date you want to the data to start from\n",
    "    - endDate: End date you want to the data to end at\n",
    "  - Returns:\n",
    "    - A pandas dataframe with the weather data\n",
    "- **retrieve_hydrometric_data**: Retrieve hydrometric stations from ECCC's API\n",
    "  - Arguments:\n",
    "    - stationNum: The station number you want to retrieve the data from (e.g. 02HB001)\n",
    "    - startDate: Start date you want to the data to start from\n",
    "    - endDate: End date you want to the data to end at\n",
    "  - Returns:\n",
    "    - A geopandas dataframe with the flow data from the station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "jupyter": {
     "source_hidden": true
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Function to create a geopandas dataframe of a bounding box around a location\n",
    "def bbox(loc, radial_distance):\n",
    "    # Extract the x and y coordinates of the location\n",
    "    x, y = loc.values.x.item(), loc.values.y.item()\n",
    "\n",
    "    # Convert the radial distance to meters\n",
    "    radial_distance_m = radial_distance * 1000\n",
    "\n",
    "    # Define the bounding box\n",
    "    bboxCoords = [x - radial_distance_m, y - radial_distance_m, x + radial_distance_m, y + radial_distance_m]\n",
    "\n",
    "    # Convert to a polygon\n",
    "    bboxPoly = Polygon([(bboxCoords[0], bboxCoords[1]), (bboxCoords[0], bboxCoords[3]), (bboxCoords[2], bboxCoords[3]), (bboxCoords[2], bboxCoords[1])])\n",
    "\n",
    "    # Create a GeoDataFrame\n",
    "    bbox = gpd.GeoDataFrame(geometry=[bboxPoly], crs=loc.crs)\n",
    "    bbox = bbox.to_crs(epsg=4326) # Convert to WGS84 (lat/lon)\n",
    "\n",
    "    return bbox\n",
    "\n",
    "# Function that queries the weather data from the ECCC API using the bounding box and start and end years\n",
    "def retrieve_climate_stations(location, yearStart, yearEnd, radial_distance):\n",
    "    # Get the bounding box\n",
    "    boxarea = bbox(location, radial_distance + 100) # Add 100 km to the buffer to ensure stations are found\n",
    "    minx, miny, maxx, maxy = boxarea.bounds.values.tolist()[0]\n",
    "\n",
    "    # First create the URL for the API using the bounding box\n",
    "    url = f'https://api.weather.gc.ca/collections/climate-stations/items?bbox={minx},{miny},{maxx},{maxy}&lang=en-CA&f=csv'\n",
    "\n",
    "    # Get the data from the API and read it into a pandas dataframe\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # Using the IO library convert the text into a file-like object and then read it into a pandas dataframe\n",
    "    stations = pd.read_csv(io.StringIO(response.text))\n",
    "\n",
    "    # Filter the stations to only include those that have data for the specified years\n",
    "    stations['DLY_FIRST_DATE'] = pd.to_datetime(stations['DLY_FIRST_DATE'], format='ISO8601')\n",
    "    stations['DLY_LAST_DATE'] = pd.to_datetime(stations['DLY_LAST_DATE'], format='ISO8601')\n",
    "    # This will reduce the number of stations to only those that have data for the specified years\n",
    "    stations = stations[\n",
    "        (stations['DLY_FIRST_DATE'].dt.year <= yearStart) & (stations['DLY_LAST_DATE'].dt.year >= yearEnd)\n",
    "        ].reset_index(drop=True)\n",
    "    \n",
    "    # Convert the stations to a GeoDataFrame\n",
    "    stations = gpd.GeoDataFrame(stations, geometry=gpd.points_from_xy(stations.x, stations.y), crs='EPSG:4326')\n",
    "\n",
    "    # In order to just get the stations that are within the a 25km radius of the basin, we can use a buffer to \n",
    "    # reduce the number of stations. We will need to use the projected coordinate system of the basin to do this.\n",
    "    stations_pcs = stations.to_crs(location.crs)\n",
    "\n",
    "    # Calculate the distance from the basin centroid to each station\n",
    "    stations_pcs['distance (km)'] = stations_pcs.distance(location.values[0])/1000\n",
    "\n",
    "    # Cycle through each station and check if it intersects with the buffer, keep increasing size until at least\n",
    "    # 10 stations are found\n",
    "    stationsWithin = pd.DataFrame()\n",
    "    radius = 25\n",
    "    while len(stationsWithin) < 10:\n",
    "        centroid_buffer = location.buffer(radius*1000)\n",
    "        stationsWithin = stations_pcs[stations_pcs.within(centroid_buffer.iloc[0])].reset_index(drop=True)\n",
    "        if stationsWithin.empty:\n",
    "            print(f'No stations found within {radius} km')\n",
    "        radius += 5\n",
    "\n",
    "    # Sort the stations by distance, and select the first 10 stations\n",
    "    stationsWithin = stationsWithin.sort_values('distance (km)')[:10].reset_index(drop=True)\n",
    "\n",
    "    # Convert the stations back to WGS84\n",
    "    stationsWithin = stationsWithin.to_crs(epsg=4326)\n",
    "    \n",
    "    return stationsWithin\n",
    "\n",
    "# Function to download the climate data for the specified stations and years\n",
    "def retrieve_weather_data(stations, startDate, endDate):\n",
    "    # Create an empty dataframe to store the data\n",
    "    weatherData = pd.DataFrame()\n",
    "   \n",
    "    # Cycle through each year and station to get the data\n",
    "    startDate = datetime.datetime.strptime(startDate, '%Y-%m-%d')\n",
    "    endDate = datetime.datetime.strptime(endDate, '%Y-%m-%d')\n",
    "    currYear = startDate.year\n",
    "    endYear = endDate.year\n",
    "\n",
    "    # Using a while loop to cycle through each year\n",
    "    while currYear <= endYear:\n",
    "        # Cycle through each station\n",
    "        for i, stat in stations.iterrows():\n",
    "            # create the URL for the API using the station ID\n",
    "            base_url = \"https://api.weather.gc.ca/collections/climate-daily/items?f=csv&lang=en-CA\"\n",
    "            url = f\"{base_url}&STN_ID={stat['STN_ID']}&LOCAL_YEAR={currYear}&sortby=LOCAL_DATE\" # Queries added to the base URL\n",
    "            \n",
    "            # Get the data from the API and read it into a pandas dataframe\n",
    "            response = requests.get(url)\n",
    "            csvText = str(response.text) # Convert the response to a string to be read by pandas\n",
    "\n",
    "            # Using the IO library convert the text into a file-like object and then read it into a pandas dataframe\n",
    "            data = pd.read_csv(io.StringIO(csvText))\n",
    "\n",
    "            # Concatenate the data to the weatherData dataframe\n",
    "            weatherData = pd.concat([weatherData, data], ignore_index=True)\n",
    "        \n",
    "        # Increment the year\n",
    "        currYear += 1\n",
    "\n",
    "    # Convert the date column to a datetime object\n",
    "    weatherData['DATE'] = pd.to_datetime(weatherData['LOCAL_DATE'], format='ISO8601')\n",
    "\n",
    "    # Filter the data to only include the dates between the start and end date\n",
    "    weatherData = weatherData[(weatherData['DATE'] >= startDate) & (weatherData['DATE'] <= endDate)]\n",
    "        \n",
    "    return weatherData[['STATION_NAME', 'DATE', 'MEAN_TEMPERATURE', 'TOTAL_PRECIPITATION']] # Return only the columns of interest\n",
    "\n",
    "# Function to retrieve the hydrometric stations from nearby the basin centroid using the ECCC API\n",
    "def retrieve_hydrometric_data(stationNum, startDate, endDate):\n",
    "    # First create the URL for the API using the bounding box\n",
    "    base_url = \"https://api.weather.gc.ca/collections/hydrometric-daily-mean/items?f=csv&lang=en-CA\"\n",
    "    url = f'{base_url}&STATION_NUMBER={stationNum}&datetime={startDate}/{endDate}' # Queries added to the base URL\n",
    "\n",
    "    # Get the data from the API and read it into a pandas dataframe\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # Using the IO library convert the text into a file-like object and then read it into a pandas dataframe\n",
    "    flowData = pd.read_csv(io.StringIO(response.text))\n",
    "\n",
    "    # Convert the date column to a datetime object\n",
    "    flowData['DATE'] = pd.to_datetime(flowData['DATE'], format='ISO8601')\n",
    "\n",
    "    return flowData[['STATION_NUMBER', 'STATION_NAME', 'DATE', 'DISCHARGE', 'DISCHARGE_SYMBOL_EN']] # Return only the columns of interest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieving Nearby Stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read in the shapefile of the basin boundary using geopandas read_file function (gpd.read_file)\n",
    "basin = ?\n",
    "\n",
    "# This will be a dataframe with a length of 3\n",
    "# Plot each row within the basin to look at it\n",
    "basin.iloc[[?]].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Select the actual boundary (correct feature) as the rest are errors generated by the delineation algorithm (review the otputs of the plots from the above cell)\n",
    "basin = basin.iloc[[?]]\n",
    "\n",
    "# Save the projected coordinate system of the basin for later use\n",
    "basin_crs = basin.crs\n",
    "\n",
    "# Get the centroid of the basin using the .centroid method on the dataframe (dataframe.centroid)\n",
    "basin_centroid = ?\n",
    "basin_centroid_coords = basin_centroid.to_crs(epsg=4326)\n",
    "\n",
    "# Reproject the layer to WGS84 (EPSG Code: 4326) since the weather guages are in WGS84. You can do this by using the to_crs method on the geopandas dataframe\n",
    "basin = basin.to_crs(epsg=?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Using the predefined functions we will retrieve the climate stations, we should create a bounding box\n",
    "# large enough to capture plenty of stations around the basin. A suggested value is 125 km, but we also\n",
    "# need to specify the years we are interested in, in this case 2000 to 2020.\n",
    "stations = retrieve_climate_stations(basin_centroid, 2000, 2020, 25)\n",
    "\n",
    "# Display the first 3 stations in the list\n",
    "stations.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Creating Thiessen Polygons for the Basin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thiessen polygons are Voroni diagrams that are used in geophysics to divide a region into polygons\n",
    "# That is why we will use the scipy library to create the Thiessen polygons (Voroni diagrams) for the stations\n",
    "\n",
    "# Create a Voronoi diagram using the station locations\n",
    "vor = Voronoi(stations[['x', 'y']])\n",
    "\n",
    "# Convert the Voronoi vertices to a list of Polygons\n",
    "thiessenPoly = [Polygon(vor.vertices[region]) for region in vor.regions if region and -1 not in region]\n",
    "\n",
    "# Create a GeoDataFrame of the Thiessen polygons\n",
    "thiessenPoly = gpd.GeoDataFrame(geometry=thiessenPoly, crs='EPSG:4326')\n",
    "\n",
    "# Clip the Thiessen polygons to a bounding box around the basin\n",
    "thiessensClip = gpd.clip(thiessenPoly, bbox(basin_centroid, 100))\n",
    "\n",
    "#Clip the Thiessen polygons to the basin boundary\n",
    "thiessensBasin = gpd.sjoin(\n",
    "    thiessensClip,\n",
    "    basin, \n",
    "    predicate='intersects'\n",
    ").drop(columns=['index_right'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spatailly join the stations to the Thiessen polygons using a spatial left join to find all stations WITHIN the theissenPolygons\n",
    "stationsThiessen = gpd.sjoin(stations, thiessenPoly, how='?', predicate='?').rename(columns={'index_right': 'Thiessen_Index'})\n",
    "\n",
    "# Display the stations with their corresponding Thiessen polygons \n",
    "stationsThiessen[['STN_ID', 'STATION_NAME', 'Thiessen_Index']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test map to see if the stations and Thiessen polygons are correct\n",
    "m = fm.Map(location=[basin_centroid_coords.y.item(), basin_centroid_coords.x.item()], zoom_start=8)\n",
    "\n",
    "# Add the basin boundary to the map\n",
    "fm.GeoJson(\n",
    "    data = basin,\n",
    "    name = 'Basin Boundary',\n",
    "    color = 'red',\n",
    "    fill = False,\n",
    "    weight = 2\n",
    ").add_to(m)\n",
    "\n",
    "# Add the all Thiessen polygons to the map\n",
    "fm.GeoJson(\n",
    "    data = thiessensClip,\n",
    "    name = 'Thiessen Polygons',\n",
    "    color = 'black',\n",
    "    fill = True,\n",
    "    fill_color = 'black',\n",
    "    fill_opacity = 0.1,\n",
    "    weight = 2\n",
    ").add_to(m)\n",
    "\n",
    "# Add only the Thiessen polygons that intersect with the basin to the map\n",
    "fm.GeoJson(\n",
    "    data = thiessensBasin,\n",
    "    color = 'blue',\n",
    "    fill = True,\n",
    "    fill_color = 'blue',\n",
    "    fill_opacity = 0.1,\n",
    "    weight = 2,\n",
    ").add_to(m)\n",
    "\n",
    "# Add the stations of interest to the map\n",
    "for i, stat in stationsThiessen.iterrows():\n",
    "    # Check if the station has a Thiessen polygon index and add the station to the map\n",
    "    if pd.notna(stat['Thiessen_Index']):\n",
    "        fm.Marker(\n",
    "            location=[stat['y'], stat['x']],\n",
    "            popup=stat['STATION_NAME'].title(),\n",
    "            icon=fm.Icon(color='cadetblue')\n",
    "        ).add_to(m)\n",
    "\n",
    "# Display the map\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there are stations that we can use to gather data from"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retreiving Climate Data for the Stations from ECCC's API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can now spatially join the stations to the Thiessen polygons that intersect with the basin using an inner join\n",
    "# This will show only the stations that are within the basin and their corresponding Thiessen polygons\n",
    "# You need to fill out the left dataframe with the stations and the right dataframe with the Thiessen polygons that are WITHIN the basin\n",
    "stationsBasin = gpd.sjoin(\n",
    "    ?,\n",
    "    ?,\n",
    "    how='inner', # Returns only values that have a match in both GeoDataFrames\n",
    "    predicate='?' # This is the spatial relationship used to join the data\n",
    ").rename(columns={'index_right': 'Thiessen_Index'}).iloc[:,:-5] # Drop the extra columns \n",
    "\n",
    "# Display the stations, IDs, names and their corresponding Thiessen polygons index\n",
    "stationsBasin[['STN_ID', 'STATION_NAME', 'Thiessen_Index']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# First we will clip the Thiessen polygons to the basin boundary using the gpd.clip function\n",
    "# Arguments: The GeoDataFrame to be clipped, The GeoDataFrame to clip with\n",
    "thiessensBasin = ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will plot the clipped Thiessen polygons on the map to see the result\n",
    "m = fm.Map(location=[basin_centroid_coords.y.item(), basin_centroid_coords.x.item()], zoom_start=8)\n",
    "\n",
    "# Add the basin boundary to the map\n",
    "fm.GeoJson(\n",
    "    data = basin,\n",
    "    name = 'Basin Boundary',\n",
    "    color = 'red',\n",
    "    fill = False,\n",
    "    weight = 2\n",
    ").add_to(m)\n",
    "\n",
    "# Add the clipped Thiessen polygons to the map\n",
    "fm.GeoJson(\n",
    "    data = thiessensBasin,\n",
    "    name = 'Thiessen Polygons',\n",
    "    color = 'black',\n",
    "    fill = True,\n",
    "    fill_color = 'black',\n",
    "    fill_opacity = 0.1,\n",
    "    weight = 2\n",
    ").add_to(m)\n",
    "\n",
    "# Display the map\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To caclulate the area of the Thiessen polygons we need to reproject the polygons to the projected coordinate system of the basin\n",
    "# then we can calculate the area of the polygons (thiessenBasin) in square meters and join it to the stations on the Thiessen_Index we have created.\n",
    "stationsBasin = stationsBasin.join(\n",
    "    # Calculate the area of the Thiessen polygons in square meters\n",
    "    ?.to_crs(basin_crs).area.rename('Area (m^2)'),\n",
    "    on='?' # Join the data on the left DataFrame using the Thiessen index column\n",
    ")\n",
    "\n",
    "# We can now calculate the weighted area of each the Thiessen polygon by dividing the area of the polygon by the total area of the basin\n",
    "stationsBasin['Weighted Area'] = stationsBasin['?'] / sum(stationsBasin['?'])\n",
    "\n",
    "# Display the new columns\n",
    "stationsBasin[['STN_ID', 'STATION_NAME', 'Thiessen_Index', 'Area (m^2)', 'Weighted Area']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precipitation Data\n",
    "Here we will be gathering the precipitation data for the stations for the year of 2010. Aftewards we will reformat the data for higher usuability, and visualize it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using a predefined function we can now retrieve the weather data for the stations within the basin\n",
    "weatherData = retrieve_weather_data(stationsBasin, '2010-01-01', '2010-12-31')\n",
    "precip = weatherData[['STATION_NAME', 'DATE', 'TOTAL_PRECIPITATION']]\n",
    "precip.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can now pivot the data to have the date as the index and the station names as the columns, with the total precipitation as the values\n",
    "# This will reshape the dataframe from long to wide format\n",
    "precip = pd.pivot_table(precip, index='DATE', columns='STATION_NAME', values='TOTAL_PRECIPITATION')\n",
    "precip.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will now add an additional column to be filled with the basin average precipitation and fill it with empty values\n",
    "precip['basin_average'] = np.nan\n",
    "precip.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can now calculate the basin average precipitation using the weighted area of each station, while also checking for missing values\n",
    "for i, row in precip.iterrows():\n",
    "    # Grab the precipitation values for each station\n",
    "    pi = row[:-1]\n",
    "\n",
    "    # Check to see if there is data from all 3 stations\n",
    "    if pi.count() == 3:\n",
    "        basin_avg = sum(pi.values * stationsBasin['Weighted Area'].values)\n",
    "    # Check to see if there is data from 2 stations\n",
    "    elif pi.count() == 2:\n",
    "        # If there are 2 stations we will assume each contributes 50% to the basin average\n",
    "        basin_avg = sum(pi.dropna()) / 2\n",
    "    # Check to see if there is data from 1 station\n",
    "    elif pi.count() == 1:\n",
    "        # If there is only 1 station we will assume it contributes 100% to the basin average\n",
    "        basin_avg = pi.dropna().values[0]\n",
    "    # If there is no data from any stations\n",
    "    else:\n",
    "        basin_avg = np.nan\n",
    "\n",
    "    # Fill the basin average column with the calculated value\n",
    "    precip.loc[i, 'basin_average'] = basin_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a bar plot of the precipitation data\n",
    "plt.style.use('ggplot') # Set the style of the plot to match one made in R\n",
    "plt.bar(\n",
    "    x = precip.index, \n",
    "    height = precip['basin_average'],\n",
    "    color='blue',\n",
    "    label='Basin Average'\n",
    ")\n",
    "plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%b-%y')) # Formates thge x-axis to show the month and year\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Basin Average Precipitation (mm)')\n",
    "plt.show() # Display the plot\n",
    "plt.close() # Close the plot to free up memory and avoid overlapping plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temperature Data\n",
    "We will now gather the mean temperature data for the stations for the year of 2010. Aftewards we will reformat the data for higher usuability, and visualize it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the weather data we can extract the mean temperature for the stations within the basin\n",
    "temp = weatherData[['STATION_NAME', 'DATE', 'MEAN_TEMPERATURE']]\n",
    "temp = pd.pivot_table(temp, index='DATE', columns='STATION_NAME', values='MEAN_TEMPERATURE')\n",
    "temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a bar plot of the precipitation data\n",
    "plt.style.use('ggplot') # Set the style of the plot to match one made in R\n",
    "plt.bar(\n",
    "    x = temp.index, \n",
    "    height = temp['MEAN_TEMPERATURE'],\n",
    "    color='red',\n",
    "    label='Temperature'\n",
    ")\n",
    "plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%b-%y')) # Formates thge x-axis to show the month and year\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Temperature (Â°C)')\n",
    "plt.show() # Display the plot\n",
    "plt.close() # Close the plot to free up memory and avoid overlapping plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieving Hydrometric Flow Data for the basin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the flows for the \"Bow River Station\" (05BB001) using the retrieve_hydrometric_data function for the year of 2010\n",
    "flowData = retrieve_hydrometric_data(?)\n",
    "flowData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('ggplot') # Set the style of the plot to match one made in R\n",
    "plt.plot(\n",
    "    flowData['DATE'],\n",
    "    flowData['DISCHARGE'],\n",
    "    color='red',\n",
    "    label='Discharge'\n",
    ")\n",
    "plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%b-%y')) # Formates thge x-axis to show the month and year\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Discharge (m\\u00b3/s)') # Unicode allows for superscript\n",
    "plt.show() # Display the plot\n",
    "plt.close() # Close the plot to free up memory and avoid overlapping plots"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
